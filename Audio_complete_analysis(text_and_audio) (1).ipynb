{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwqJd63_f20i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOl0w5u-gOFV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RneDMDC2gOID",
        "outputId": "f14874b5-63db-4c6f-da54-2b7b923556d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-4e5naycs\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-4e5naycs\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2->openai-whisper==20240930) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803669 sha256=abc7a014f8811be549089928c2ad388b733bd0132d24b1d381f8a9940d595d1b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1lf6ia5y/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYvHUJX1gfB0",
        "outputId": "17995d78-a38f-41d3-8562-2b459b2298f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Collecting pytest-warnings\n",
            "  Downloading pytest_warnings-0.3.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from pytest-warnings) (8.3.4)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->pytest-warnings) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest->pytest-warnings) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->pytest-warnings) (1.5.0)\n",
            "Downloading pytest_warnings-0.3.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Installing collected packages: pytest-warnings\n",
            "Successfully installed pytest-warnings-0.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa\n",
        "!pip install pytest-warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q2RASnEBf3hM",
        "outputId": "de672825-1184-4a81-c46a-2d96b3a62f6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.40)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.16-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.25.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.69.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_google_genai-2.0.11-py3-none-any.whl (39 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.16-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.16 langchain-google-genai-2.0.11\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "a68a23ebfb934cf5b79e776ad8168518",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvXIh4ZRg6Le"
      },
      "outputs": [],
      "source": [
        "!pip install audioop-lts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwkUcLtogSE0",
        "outputId": "8f13df29-f183-4a07-9011-ee4a80a81094"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPzGZ_sL2bcz"
      },
      "source": [
        "## Main code Modified (11/3/2025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ynwJ0dEIUzH"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import detect_silence\n",
        "from pydub.utils import db_to_float\n",
        "import whisper\n",
        "import warnings\n",
        "import wave\n",
        "import audioop\n",
        "import json\n",
        "# import psutil\n",
        "# from flask import Flask, jsonify, request\n",
        "import os\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "# app = Flask(__name__)\n",
        "\n",
        "google_api_key = ''\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model='gemini-1.5-pro-latest', temperature=0.6, google_api_key=google_api_key)\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "conversation_chain = ConversationChain(llm=llm, memory=memory)\n",
        "\n",
        "whisper_model = whisper.load_model(\"small\")\n",
        "\n",
        "# Load audio file\n",
        "def load_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    return audio, sr\n",
        "\n",
        "# Convert NumPy array to AudioSegment\n",
        "def numpy_to_audiosegment(audio, sr):\n",
        "    audio = (audio * (2**15 - 1)).astype(np.int16)  # Convert to 16-bit PCM format\n",
        "    audio_segment = AudioSegment(\n",
        "        audio.tobytes(),\n",
        "        frame_rate=sr,\n",
        "        sample_width=audio.dtype.itemsize,\n",
        "        channels=1\n",
        "    )\n",
        "    return audio_segment\n",
        "\n",
        "# Analyze pitch and tone\n",
        "def analyze_pitch_and_tone(audio, sr):\n",
        "    pitches, magnitudes = librosa.core.piptrack(y=audio, sr=sr)\n",
        "    pitch_mean = np.mean(pitches[pitches > 0])  # Ignore zero values\n",
        "    pitch_std = np.std(pitches[pitches > 0])\n",
        "    return pitch_mean, pitch_std\n",
        "\n",
        "# Analyze speech rate\n",
        "def analyze_speech_rate(transcript, audio_duration):\n",
        "    words = transcript.split()\n",
        "    word_count = len(words)\n",
        "    speech_rate = word_count / audio_duration\n",
        "    return speech_rate\n",
        "\n",
        "# Detect pauses and fillers\n",
        "def detect_pauses_and_fillers(audio_segment, transcript):\n",
        "    # Detect silence (pauses)\n",
        "    silence_threshold = -40  # dB\n",
        "    min_silence_len = 500  # ms\n",
        "    pauses = detect_silence(audio_segment, min_silence_len, silence_threshold, 1)\n",
        "\n",
        "    # Count fillers (\"um\", \"uh\")\n",
        "    fillers = [\"um\", \"uh\"]\n",
        "    filler_count = sum(transcript.lower().count(filler) for filler in fillers)\n",
        "\n",
        "    return pauses, filler_count\n",
        "\n",
        "# Analyze volume and clarity\n",
        "def analyze_volume_and_clarity(audio):\n",
        "    rms = librosa.feature.rms(y=audio)[0]\n",
        "    volume_mean = np.mean(rms)\n",
        "    volume_std = np.std(rms)\n",
        "    return volume_mean, volume_std\n",
        "\n",
        "# Audio to text using Whisper\n",
        "def transcribe_audio_whisper(file_path):\n",
        "    warnings.filterwarnings(\"ignore\", message=\"You are using `torch.load` with `weights_only=False`\")\n",
        "    print(\"Transcribing audio with Whisper...\")\n",
        "    result = whisper_model.transcribe(file_path, fp16=False)\n",
        "    return result[\"text\"]\n",
        "\n",
        "def analyze_audio(file_path):\n",
        "    audio, sr = load_audio(file_path)\n",
        "    audio_duration = librosa.get_duration(y=audio, sr=sr)\n",
        "\n",
        "    # Convert audio to AudioSegment\n",
        "    audio_segment = numpy_to_audiosegment(audio, sr)\n",
        "\n",
        "    # Transcribe audio with Whisper\n",
        "    transcript = transcribe_audio_whisper(file_path)\n",
        "    if not transcript:\n",
        "        print(\"No transcript available for analysis.\")\n",
        "        return\n",
        "\n",
        "    # Analyze features\n",
        "    pitch_mean, pitch_std = analyze_pitch_and_tone(audio, sr)\n",
        "    speech_rate = analyze_speech_rate(transcript, audio_duration)\n",
        "    pauses, filler_count = detect_pauses_and_fillers(audio_segment, transcript)\n",
        "    volume_mean, volume_std = analyze_volume_and_clarity(audio)\n",
        "\n",
        "    # Analyze basic properties of the new audio file\n",
        "    new_audio_properties = {}\n",
        "    try:\n",
        "        with wave.open(file_path, 'r') as audio_:\n",
        "            # Extract basic audio properties\n",
        "            new_audio_properties['frame_rate'] = audio_.getframerate()\n",
        "            new_audio_properties['n_frames'] = audio_.getnframes()\n",
        "            new_audio_properties['duration'] = audio_.getnframes() / audio_.getframerate()\n",
        "\n",
        "            # Compute average loudness (RMS) and silence ratio\n",
        "            frames = audio_.readframes(audio_.getnframes())\n",
        "            rms = audioop.rms(frames, audio_.getsampwidth())  # Root mean square of the audio signal\n",
        "            silent_frames = sum(\n",
        "                audioop.rms(frames[i:i + audio_.getsampwidth()], audio_.getsampwidth()) < 1000\n",
        "                for i in range(0, len(frames), audio_.getsampwidth())\n",
        "            )\n",
        "            silence_ratio = silent_frames / len(frames)\n",
        "    except Exception as e:\n",
        "        new_audio_properties['error'] = str(e)\n",
        "\n",
        "    # Package detailed results for the new audio file\n",
        "    new_audio_properties.update({\n",
        "        \"average_loudness\": rms,\n",
        "        \"silence_ratio\": silence_ratio,\n",
        "        \"speech_detected\": silence_ratio < 0.5,  # Assumes speech if less than 50% silence\n",
        "    })\n",
        "\n",
        "    # Output the analysis results\n",
        "    print(new_audio_properties)\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    # Pauses condition\n",
        "    if 10 <= len(pauses) <= 20:\n",
        "        scores.append('Average')\n",
        "    elif 1 <= len(pauses) <= 10:\n",
        "        scores.append('Good')\n",
        "    elif len(pauses) == 0:\n",
        "        scores.append('Excellent')\n",
        "    elif len(pauses) > 20:\n",
        "        scores.append('Bad')\n",
        "\n",
        "    # Speech rate condition\n",
        "    if speech_rate <= 1.25:\n",
        "        scores.append('Bad')\n",
        "    elif 1.25 <= speech_rate <= 2.05:\n",
        "        scores.append('Average')\n",
        "    elif 2.05 <= speech_rate <= 3.0:\n",
        "        scores.append('Good')\n",
        "    else:\n",
        "        scores.append('Excellent')\n",
        "\n",
        "    # Silence Ratio\n",
        "    if silence_ratio > 0.45:\n",
        "        scores.append('Bad')\n",
        "    elif 0 <= silence_ratio <= 0.20:\n",
        "        scores.append('Excellent')\n",
        "    elif 0.20 < silence_ratio <= 0.35:\n",
        "        scores.append('Good')\n",
        "    elif 0.35 < silence_ratio <= 0.45:\n",
        "        scores.append('Average')\n",
        "\n",
        "    # Pitch mean\n",
        "    if pitch_mean <= 732:\n",
        "        scores.append('Bad')\n",
        "    elif 732 < pitch_mean <= 900:\n",
        "        scores.append('Average')\n",
        "    elif pitch_mean > 900:\n",
        "        scores.append('Good')\n",
        "\n",
        "    # Pitch Std\n",
        "    if pitch_std <= 723:\n",
        "        scores.append('Bad')\n",
        "    elif 723 < pitch_std <= 900:\n",
        "        scores.append('Average')\n",
        "    elif pitch_std > 900:\n",
        "        scores.append('Good')\n",
        "\n",
        "    print(scores)\n",
        "\n",
        "    if pitch_mean > 1350 or rms > 2800:\n",
        "        pitch_mean = pitch_mean / 1.25\n",
        "        rms = rms / 1.75\n",
        "\n",
        "        Average_positive = [pitch_mean, pitch_std, speech_rate, rms]\n",
        "        Average_negative = [len(pauses), (silence_ratio * 10)]\n",
        "\n",
        "        Scaled_positive = sum(Average_positive) / 4\n",
        "        Scaled_negative = sum(Average_negative) / 2\n",
        "\n",
        "        Scaled_positive_1000 = Scaled_positive / 1000\n",
        "        Scaled_negative_100 = Scaled_negative / 100\n",
        "\n",
        "        final_conversion_p = Scaled_positive_1000 * 0.25\n",
        "        final_conversion_n = Scaled_negative_100 * 0.50\n",
        "\n",
        "        Result = final_conversion_p - final_conversion_n\n",
        "        print(final_conversion_p, '\\n', final_conversion_n)\n",
        "\n",
        "        Result_new = Result * 2.5\n",
        "        final_result = Result_new * 100\n",
        "        # print(f'Your final Audio Score is {final_result}')\n",
        "\n",
        "    else:\n",
        "        Average_positive = [pitch_mean, pitch_std, speech_rate]\n",
        "        Average_negative = [len(pauses), (silence_ratio * 10)]\n",
        "\n",
        "        Scaled_positive = sum(Average_positive) / 3\n",
        "        Scaled_negative = sum(Average_negative) / 2\n",
        "\n",
        "        Scaled_positive_1000 = Scaled_positive / 1000\n",
        "        Scaled_negative_100 = Scaled_negative / 100\n",
        "\n",
        "        final_conversion_p = Scaled_positive_1000 * 0.25\n",
        "        final_conversion_n = Scaled_negative_100 * 0.50\n",
        "\n",
        "        Result = final_conversion_p - final_conversion_n\n",
        "        Result_new = Result * 2.5\n",
        "        final_result = Result_new * 100\n",
        "\n",
        "\n",
        "\n",
        "    audio_score = []\n",
        "\n",
        "    if scores.count('Bad') >= 2:\n",
        "        final_result_new = final_result / 2\n",
        "        audio_score.append(final_result_new)\n",
        "        print(f'Your final Audio Score is {final_result_new}')\n",
        "    elif scores.count('Bad') == 1:\n",
        "        decrease = final_result * (1 / 4)\n",
        "        final_result_new = final_result - decrease\n",
        "        audio_score.append(final_result_new)\n",
        "        print(f'Your final Audio Score is {final_result_new}')\n",
        "    else:\n",
        "        print(f'Your final Audio Score is {final_result}')\n",
        "        audio_score.append(final_result)\n",
        "\n",
        "      # Define the prompt for analysis\n",
        "    analysis_prompt = f\"\"\" {transcript} analysis the text based on grammar mistakes, fluency, clarity , professional tone and  overall rate it and rate out of 100 this is the text of interviewer analysis it completely Provide me only the scores don't give unnecessary text also detect irrelevant words means(out of context words or topic like here is candidate self introduction text if find irrelevant topic than self introduction) and give me score if there are out of context words and drop overall score if there is irrelvancy return only overall score not return any other score give me final score by decreasing the (give me irrelevancy score in positive number only don't give negative number return in json format)\n",
        "    \"\"\"\n",
        "    print(transcript)\n",
        "\n",
        "    def chat_with_bot(user_input):\n",
        "        formatted_prompt = analysis_prompt.format(text=user_input)\n",
        "        response = conversation_chain.run(input=formatted_prompt)\n",
        "        return response\n",
        "\n",
        "    response = chat_with_bot(user_input=analysis_prompt)\n",
        "\n",
        "    start = response.replace(\"```json\", \"\")\n",
        "    end = start.replace(\"```\", \"\")\n",
        "    end1 = json.loads(end)\n",
        "    print(end1)\n",
        "    print(end1[\"overall\"] - end1[\"irrelevancy\"])\n",
        "    text_final_score = end1[\"overall\"] - end1[\"irrelevancy\"]\n",
        "    audio_final_score = audio_score[0]\n",
        "\n",
        "    overall_final_score = (text_final_score + audio_final_score) / 2\n",
        "    print(f\"overall final score is {overall_final_score}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    audio_file = \"/content/silent audio1.wav\"\n",
        "    analyze_audio(audio_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiM4gLorozCk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5Zn9NMqf3kL",
        "outputId": "4fe0fb11-609f-4bda-9780-fc129ddfbdaa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:05<00:00, 93.1MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribing audio with Whisper...\n",
            "{'frame_rate': 48000, 'n_frames': 2022912, 'duration': 42.144, 'average_loudness': 4791, 'silence_ratio': 0.23425981950771957, 'speech_detected': True}\n",
            "Analysis Results:\n",
            "Pitch Mean: 1289.36, Pitch Std: 1015.02\n",
            "Speech Rate: 2.56 words per second\n",
            "Number of Pauses: 0\n",
            "Filler Count: 0\n",
            "Volume Mean: 0.09, Volume Std: 0.06\n",
            "Transcript:  My name is Kaneshka. I am currently pursuing my BICOM along with my studies. I have industrial experience working at VSCO HR private limited. This role has helped me help me in develop strong communication skills, teamwork and problem-solving abilities. I am a quick learner always looking to improve my skills and take on new challenges. I am excited to apply my knowledge and experience to a new role and contribute to a team. I am confident that my strong work ethic, positive attitude and passion of learning will make me a valuable asset to any organization. I am looking forward to discussing my qualification further. Thank you.\n",
            "Your final Audio Score is 48.68708944582943\n",
            " My name is Kaneshka. I am currently pursuing my BICOM along with my studies. I have industrial experience working at VSCO HR private limited. This role has helped me help me in develop strong communication skills, teamwork and problem-solving abilities. I am a quick learner always looking to improve my skills and take on new challenges. I am excited to apply my knowledge and experience to a new role and contribute to a team. I am confident that my strong work ethic, positive attitude and passion of learning will make me a valuable asset to any organization. I am looking forward to discussing my qualification further. Thank you.\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import detect_silence\n",
        "from pydub.utils import db_to_float\n",
        "import whisper\n",
        "import warnings\n",
        "import wave\n",
        "import audioop\n",
        "\n",
        "# Load Whisper medium model\n",
        "whisper_model = whisper.load_model(\"small\")\n",
        "\n",
        "# Load audio file\n",
        "def load_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    return audio, sr\n",
        "\n",
        "# Convert NumPy array to AudioSegment\n",
        "def numpy_to_audiosegment(audio, sr):\n",
        "    audio = (audio * (2**15 - 1)).astype(np.int16)  # Convert to 16-bit PCM format\n",
        "    audio_segment = AudioSegment(\n",
        "        audio.tobytes(),\n",
        "        frame_rate=sr,\n",
        "        sample_width=audio.dtype.itemsize,\n",
        "        channels=1\n",
        "    )\n",
        "    return audio_segment\n",
        "\n",
        "# Analyze pitch and tone\n",
        "def analyze_pitch_and_tone(audio, sr):\n",
        "    pitches, magnitudes = librosa.core.piptrack(y=audio, sr=sr)\n",
        "    pitch_mean = np.mean(pitches[pitches > 0])  # Ignore zero values\n",
        "    pitch_std = np.std(pitches[pitches > 0])\n",
        "    return pitch_mean, pitch_std\n",
        "\n",
        "# Analyze speech rate\n",
        "def analyze_speech_rate(transcript, audio_duration):\n",
        "    words = transcript.split()\n",
        "    word_count = len(words)\n",
        "    speech_rate = word_count / audio_duration\n",
        "    return speech_rate\n",
        "\n",
        "# Detect pauses and fillers\n",
        "def detect_pauses_and_fillers(audio_segment, transcript):\n",
        "    # Detect silence (pauses)\n",
        "    silence_threshold = -40  # dB\n",
        "    min_silence_len = 500  # ms\n",
        "    pauses = detect_silence(audio_segment, min_silence_len, silence_threshold, 1)\n",
        "\n",
        "    # Count fillers (\"um\", \"uh\")\n",
        "    fillers = [\"um\", \"uh\"]\n",
        "    filler_count = sum(transcript.lower().count(filler) for filler in fillers)\n",
        "\n",
        "    return pauses, filler_count\n",
        "\n",
        "# Analyze volume and clarity\n",
        "def analyze_volume_and_clarity(audio):\n",
        "    rms = librosa.feature.rms(y=audio)[0]\n",
        "    volume_mean = np.mean(rms)\n",
        "    volume_std = np.std(rms)\n",
        "    return volume_mean, volume_std\n",
        "\n",
        "#Audio to text using Whisper\n",
        "def transcribe_audio_whisper(file_path):\n",
        "    warnings.filterwarnings(\"ignore\", message=\"You are using `torch.load` with `weights_only=False`\")\n",
        "    print(\"Transcribing audio with Whisper...\")\n",
        "    result = whisper_model.transcribe(file_path, fp16=False)\n",
        "    return result[\"text\"]\n",
        "\n",
        "\n",
        "def analyze_audio(file_path):\n",
        "    audio, sr = load_audio(file_path)\n",
        "    audio_duration = librosa.get_duration(y=audio, sr=sr)\n",
        "\n",
        "    # Convert audio to AudioSegment\n",
        "    audio_segment = numpy_to_audiosegment(audio, sr)\n",
        "\n",
        "    # Transcribe audio with Whisper\n",
        "    transcript = transcribe_audio_whisper(file_path)\n",
        "    if not transcript:\n",
        "        print(\"No transcript available for analysis.\")\n",
        "        return\n",
        "\n",
        "    # Analyze features\n",
        "    pitch_mean, pitch_std = analyze_pitch_and_tone(audio, sr)\n",
        "    speech_rate = analyze_speech_rate(transcript, audio_duration)\n",
        "    pauses, filler_count = detect_pauses_and_fillers(audio_segment, transcript)\n",
        "    volume_mean, volume_std = analyze_volume_and_clarity(audio)\n",
        "\n",
        "\n",
        "\n",
        "    # Analyze basic properties of the new audio file\n",
        "    new_audio_properties = {}\n",
        "    try:\n",
        "        with wave.open(audio_file, 'r') as audio_:\n",
        "            # Extract basic audio properties\n",
        "            # new_audio_properties['channels'] = audio_file.getnchannels()\n",
        "            # new_audio_properties['sample_width'] = audio_file.getsampwidth()\n",
        "            new_audio_properties['frame_rate'] = audio_.getframerate()\n",
        "            new_audio_properties['n_frames'] = audio_.getnframes()\n",
        "            new_audio_properties['duration'] = audio_.getnframes() / audio_.getframerate()\n",
        "\n",
        "            # Compute average loudness (RMS) and silence ratio\n",
        "            frames = audio_.readframes(audio_.getnframes())\n",
        "            rms = audioop.rms(frames, audio_.getsampwidth())  # Root mean square of the audio signal\n",
        "            silent_frames = sum(\n",
        "                audioop.rms(frames[i:i + audio_.getsampwidth()], audio_.getsampwidth()) < 1000\n",
        "                for i in range(0, len(frames), audio_.getsampwidth())\n",
        "            )\n",
        "            silence_ratio = silent_frames / len(frames)\n",
        "    except Exception as e:\n",
        "        new_audio_properties['error'] = str(e)\n",
        "\n",
        "    # Package detailed results for the new audio file\n",
        "    new_audio_properties.update({\n",
        "        \"average_loudness\": rms,\n",
        "        \"silence_ratio\": silence_ratio,\n",
        "        \"speech_detected\": silence_ratio < 0.5,  # Assumes speech if less than 50% silence\n",
        "    })\n",
        "\n",
        "    # Output the analysis results\n",
        "    print(new_audio_properties)\n",
        "\n",
        "    # results\n",
        "    print(\"Analysis Results:\")\n",
        "    print(f\"Pitch Mean: {pitch_mean:.2f}, Pitch Std: {pitch_std:.2f}\")\n",
        "    print(f\"Speech Rate: {speech_rate:.2f} words per second\")\n",
        "    print(f\"Number of Pauses: {len(pauses)}\")\n",
        "    print(f\"Filler Count: {filler_count}\")\n",
        "    print(f\"Volume Mean: {volume_mean:.2f}, Volume Std: {volume_std:.2f}\")\n",
        "    print(f\"Transcript: {transcript}\")\n",
        "\n",
        "    if pitch_mean>1350 or rms>2800:\n",
        "      pitch_mean = pitch_mean/1.25\n",
        "      rms = rms/1.85\n",
        "\n",
        "      Average_positive = [pitch_mean,pitch_std,speech_rate,rms]\n",
        "      Average_negative = [len(pauses),(silence_ratio*10)]\n",
        "\n",
        "\n",
        "      Scaled_positive = sum(Average_positive)/4\n",
        "      Scaled_negative = sum(Average_negative)/2\n",
        "\n",
        "      Scaled_positive_1000 = Scaled_positive/1000\n",
        "      Scaled_negative_100 = Scaled_negative/50\n",
        "\n",
        "\n",
        "      final_conversion_p = Scaled_positive_1000*0.25\n",
        "      final_conversion_n = Scaled_negative_100*0.50\n",
        "\n",
        "\n",
        "      Result = final_conversion_p-final_conversion_n\n",
        "      Result_new = Result*1.75\n",
        "      final_result = Result_new*100\n",
        "      print(f'Your final Audio Score is {final_result}')\n",
        "\n",
        "    else:\n",
        "      Average_positive = [pitch_mean,pitch_std,speech_rate,rms]\n",
        "      Average_negative = [len(pauses),(silence_ratio*10)]\n",
        "\n",
        "\n",
        "      Scaled_positive = sum(Average_positive)/4\n",
        "      Scaled_negative = sum(Average_negative)/2\n",
        "\n",
        "      Scaled_positive_1000 = Scaled_positive/1000\n",
        "      Scaled_negative_100 = Scaled_negative/50\n",
        "\n",
        "\n",
        "      final_conversion_p = Scaled_positive_1000*0.25\n",
        "      final_conversion_n = Scaled_negative_100*0.50\n",
        "\n",
        "\n",
        "      Result = final_conversion_p-final_conversion_n\n",
        "      # Result_new = Result*2.5\n",
        "      final_result = Result*100\n",
        "      if final_result <=0:\n",
        "        print('Your score is 10')\n",
        "      else:\n",
        "        print(f'Your final Audio Score is {final_result}')\n",
        "\n",
        "\n",
        "    # print(f\"Results:{Result*2.5}\")\n",
        "    # print(f)\n",
        "\n",
        "    # print(Average_positive)\n",
        "\n",
        "    # import os\n",
        "    # from langchain.chains import ConversationChain\n",
        "    # from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "    # from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "    # # API KEY\n",
        "    # google_api_key = ''\n",
        "\n",
        "    # # Llm model google genai\n",
        "    # llm = ChatGoogleGenerativeAI(model='gemini-1.5-pro-latest', temperature=0.6, google_api_key=google_api_key)\n",
        "\n",
        "    # # Set up memory and conversation chain\n",
        "    # memory = ConversationBufferMemory()\n",
        "    # conversation_chain = ConversationChain(llm=llm, memory=memory)\n",
        "\n",
        "    # # Define the prompt for analysis\n",
        "    # analysis_prompt = f\"\"\" {transcript} analysis the text based on grammar mistakes, fluency, clarity , professional tone and  overall rate it and rate out of 10 this is the text of interviewer analysis it completely Provide me only the scores don't give unnecessary text\n",
        "\n",
        "    # \"\"\"\n",
        "\n",
        "\n",
        "    # def chat_with_bot(user_input):\n",
        "    #     # Format the analysis prompt with user input\n",
        "    #     formatted_prompt = analysis_prompt.format(text=user_input)\n",
        "    #     response = conversation_chain.run(input=formatted_prompt)\n",
        "    #     return response\n",
        "\n",
        "    # print(f\"Your Audio Text score is \\n {chat_with_bot(user_input=analysis_prompt)}\")\n",
        "\n",
        "\n",
        "    print(transcript)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    audio_file = \"/content/kanisha_n.wav\"\n",
        "    analyze_audio(audio_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmBzCd8OpPFT",
        "outputId": "f18caa04-aca6-47a4-d2de-db22d965c6b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.11.11\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ou3pFhqIDFa",
        "outputId": "8080ca67-8357-4d32-b17e-6cd2ffc7ea7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bad\n"
          ]
        }
      ],
      "source": [
        "number = 21\n",
        "if 10 <= number <= 20:\n",
        "    print('Average')\n",
        "elif 1<= number <=10:\n",
        "  print('Good')\n",
        "elif number == 0:\n",
        "    print('Excellent')\n",
        "elif number > 20:\n",
        "    print('Bad')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9X0NjnBY_cF"
      },
      "source": [
        "## Main or Updated code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hHjmIfYHg4S",
        "outputId": "d029207f-d76d-4adc-bd03-2373597b7098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribing audio with Whisper...\n",
            "Pauses Score\n",
            "Speech rate Score\n",
            "Silence Ratio Score\n",
            "Pitch mean Score\n",
            "Pitch Std score\n",
            "0.29917248240424443 \n",
            " 0.00585649548769299\n",
            "Your final Audio Score is 73.32899672913786\n",
            "\n",
            "Grammar: 7/10\n",
            "Fluency: 6/10\n",
            "Clarity: 8/10\n",
            "Professional Tone: 9/10\n",
            "Irrelevant Words: 9/10 (Minor issue with \"along with my studies\" - redundant after \"pursuing my B.Com\")\n",
            "\n",
            "Overall: 7.8/10 \n",
            "Your Audio Text score is \n",
            " Grammar: 7/10\n",
            "Fluency: 6/10\n",
            "Clarity: 8/10\n",
            "Professional Tone: 9/10\n",
            "Irrelevant Words: 9/10\n",
            "\n",
            "Overall: 7.8/10\n",
            " overall_text score\n",
            " My name is Kanishka. I am currently pursuing my B.Com along with my studies. I have industrial experience working at Wisco HR Private Limited. This role has helped me in developing strong communication skills, teamwork and problem solving abilities. I am a quick learner, always looking to improve my skills and take on new challenges. I am excited to apply my knowledge and experience to a new role and contribute to a team. I am confident that my strong work ethic, positive attitude and passion of learning will make me a valuable asset to any organization. I am looking forward to discussing my qualification further. Thank you.\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import detect_silence\n",
        "from pydub.utils import db_to_float\n",
        "import whisper\n",
        "import warnings\n",
        "import wave\n",
        "import audioop\n",
        "\n",
        "#  Whisper medium\n",
        "whisper_model = whisper.load_model(\"medium\")\n",
        "\n",
        "# Load audio file\n",
        "def load_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    return audio, sr\n",
        "\n",
        "# Convert NumPy array to AudioSegment\n",
        "def numpy_to_audiosegment(audio, sr):\n",
        "    audio = (audio * (2**15 - 1)).astype(np.int16)  # Convert to 16-bit PCM format\n",
        "    audio_segment = AudioSegment(\n",
        "        audio.tobytes(),\n",
        "        frame_rate=sr,\n",
        "        sample_width=audio.dtype.itemsize,\n",
        "        channels=1\n",
        "    )\n",
        "    return audio_segment\n",
        "\n",
        "# Analyze pitch and tone\n",
        "def analyze_pitch_and_tone(audio, sr):\n",
        "    pitches, magnitudes = librosa.core.piptrack(y=audio, sr=sr)\n",
        "    pitch_mean = np.mean(pitches[pitches > 0])  # Ignore zero values\n",
        "    pitch_std = np.std(pitches[pitches > 0])\n",
        "    return pitch_mean, pitch_std\n",
        "\n",
        "# Analyze speech rate\n",
        "def analyze_speech_rate(transcript, audio_duration):\n",
        "    words = transcript.split()\n",
        "    word_count = len(words)\n",
        "    speech_rate = word_count / audio_duration\n",
        "    return speech_rate\n",
        "\n",
        "# Detect pauses and fillers\n",
        "def detect_pauses_and_fillers(audio_segment, transcript):\n",
        "    # Detect silence (pauses)\n",
        "    silence_threshold = -40  # dB\n",
        "    min_silence_len = 500  # ms\n",
        "    pauses = detect_silence(audio_segment, min_silence_len, silence_threshold, 1)\n",
        "\n",
        "    # Count fillers (\"um\", \"uh\")\n",
        "    fillers = [\"um\", \"uh\"]\n",
        "    filler_count = sum(transcript.lower().count(filler) for filler in fillers)\n",
        "\n",
        "    return pauses, filler_count\n",
        "\n",
        "# Analyze volume and clarity\n",
        "def analyze_volume_and_clarity(audio):\n",
        "    rms = librosa.feature.rms(y=audio)[0]\n",
        "    volume_mean = np.mean(rms)\n",
        "    volume_std = np.std(rms)\n",
        "    return volume_mean, volume_std\n",
        "\n",
        "#Audio to text using Whisper\n",
        "def transcribe_audio_whisper(file_path):\n",
        "    warnings.filterwarnings(\"ignore\", message=\"You are using `torch.load` with `weights_only=False`\")\n",
        "    print(\"Transcribing audio with Whisper...\")\n",
        "    result = whisper_model.transcribe(file_path, fp16=False)\n",
        "    return result[\"text\"]\n",
        "\n",
        "\n",
        "def analyze_audio(file_path):\n",
        "    audio, sr = load_audio(file_path)\n",
        "    audio_duration = librosa.get_duration(y=audio, sr=sr)\n",
        "\n",
        "    # Convert audio to AudioSegment\n",
        "    audio_segment = numpy_to_audiosegment(audio, sr)\n",
        "\n",
        "    # Transcribe audio with Whisper\n",
        "    transcript = transcribe_audio_whisper(file_path)\n",
        "    if not transcript:\n",
        "        print(\"No transcript available for analysis.\")\n",
        "        return\n",
        "\n",
        "    # Analyze features\n",
        "    pitch_mean, pitch_std = analyze_pitch_and_tone(audio, sr)\n",
        "    speech_rate = analyze_speech_rate(transcript, audio_duration)\n",
        "    pauses, filler_count = detect_pauses_and_fillers(audio_segment, transcript)\n",
        "    volume_mean, volume_std = analyze_volume_and_clarity(audio)\n",
        "\n",
        "\n",
        "\n",
        "    # Analyze basic properties of the new audio file\n",
        "    new_audio_properties = {}\n",
        "    try:\n",
        "        with wave.open(audio_file, 'r') as audio_:\n",
        "            # Extract basic audio properties\n",
        "            # new_audio_properties['channels'] = audio_file.getnchannels()\n",
        "            # new_audio_properties['sample_width'] = audio_file.getsampwidth()\n",
        "            new_audio_properties['frame_rate'] = audio_.getframerate()\n",
        "            new_audio_properties['n_frames'] = audio_.getnframes()\n",
        "            new_audio_properties['duration'] = audio_.getnframes() / audio_.getframerate()\n",
        "\n",
        "            # Compute average loudness (RMS) and silence ratio\n",
        "            frames = audio_.readframes(audio_.getnframes())\n",
        "            rms = audioop.rms(frames, audio_.getsampwidth())  # Root mean square of the audio signal\n",
        "            silent_frames = sum(\n",
        "                audioop.rms(frames[i:i + audio_.getsampwidth()], audio_.getsampwidth()) < 1000\n",
        "                for i in range(0, len(frames), audio_.getsampwidth())\n",
        "            )\n",
        "            silence_ratio = silent_frames / len(frames)\n",
        "    except Exception as e:\n",
        "        new_audio_properties['error'] = str(e)\n",
        "\n",
        "    # Package detailed results for the new audio file\n",
        "    new_audio_properties.update({\n",
        "        \"average_loudness\": rms,\n",
        "        \"silence_ratio\": silence_ratio,\n",
        "        \"speech_detected\": silence_ratio < 0.5,  # Assumes speech if less than 50% silence\n",
        "    })\n",
        "\n",
        "    # Output the analysis results\n",
        "    # print(new_audio_properties)\n",
        "\n",
        "    # results\n",
        "    # print(\"Analysis Results:\")\n",
        "    # print(f\"Pitch Mean: {pitch_mean:.2f}, Pitch Std: {pitch_std:.2f}\")\n",
        "    # print(f\"Speech Rate: {speech_rate:.2f} words per second\")\n",
        "    # print(f\"Number of Pauses: {len(pauses)}\")\n",
        "    # print(f\"Filler Count: {filler_count}\")\n",
        "    # print(f\"Volume Mean: {volume_mean:.2f}, Volume Std: {volume_std:.2f}\")\n",
        "    # print(f\"Transcript: {transcript}\")\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    # Pauses conditon\n",
        "    print('Pauses Score')\n",
        "    if 10 <= len(pauses) <= 20:\n",
        "        scores.append('Average')\n",
        "        # print('Average')\n",
        "    elif 1<=len(pauses)<=10:\n",
        "      scores.append('Good')\n",
        "      # print('GOOD')\n",
        "    elif len(pauses) == 0:\n",
        "        scores.append('Excellent')\n",
        "        # print('Excellent')\n",
        "    elif len(pauses) > 20:\n",
        "        scores.append('Bad')\n",
        "        # print('Bad')\n",
        "\n",
        "    # Speech rate condition\n",
        "    print('Speech rate Score')\n",
        "    if speech_rate<=1.25:\n",
        "      scores.append('Bad')\n",
        "      # print('Bad')\n",
        "    elif 1.25<=speech_rate<=2.05:\n",
        "      scores.append('Average')\n",
        "      # print('Average')\n",
        "    elif 2.05<=speech_rate<=3.0:\n",
        "      scores.append('Good')\n",
        "      # print('Good')\n",
        "    else:\n",
        "      scores.append('Excellent')\n",
        "      # print('Excellent')\n",
        "\n",
        "    # Silence_Ratio\n",
        "    print('Silence Ratio Score')\n",
        "    if silence_ratio>0.45:\n",
        "      scores.append('Bad')\n",
        "      # print('Bad')\n",
        "    elif 0<=silence_ratio<=0.20:\n",
        "      scores.append('Excellent')\n",
        "      # print('Excellent')\n",
        "    elif 0.20<silence_ratio<=0.35:\n",
        "      scores.append('Good')\n",
        "      # print('Good')\n",
        "    elif 0.35<silence_ratio<=0.45:\n",
        "      scores.append('Average')\n",
        "      # print('Average')\n",
        "\n",
        "    # Pitch mean\n",
        "    print('Pitch mean Score')\n",
        "    if pitch_mean<=732:\n",
        "      scores.append('Bad')\n",
        "      # print('Bad')\n",
        "    elif 732<pitch_mean<=900:\n",
        "      scores.append('Average')\n",
        "      # print('Average')\n",
        "    elif pitch_mean>900:\n",
        "      scores.append('Good')\n",
        "      # print('Good')\n",
        "\n",
        "    # Pitch Std\n",
        "    print('Pitch Std score')\n",
        "    if pitch_std<=723:\n",
        "      scores.append('Bad')\n",
        "      # print('Bad')\n",
        "    elif 723<pitch_std<=900:\n",
        "      scores.append('Average')\n",
        "      # print('Average')\n",
        "    elif pitch_std>900:\n",
        "      scores.append('Good')\n",
        "      # print('Good')\n",
        "\n",
        "\n",
        "    if pitch_mean>1350 or rms>2800:\n",
        "      pitch_mean = pitch_mean/1.25\n",
        "      rms = rms/1.75\n",
        "\n",
        "      Average_positive = [pitch_mean,pitch_std,speech_rate,rms]\n",
        "      Average_negative = [len(pauses),(silence_ratio*10)]\n",
        "\n",
        "\n",
        "      Scaled_positive = sum(Average_positive)/4\n",
        "      Scaled_negative = sum(Average_negative)/2\n",
        "\n",
        "      Scaled_positive_1000 = Scaled_positive/1000\n",
        "      Scaled_negative_100 = Scaled_negative/100\n",
        "\n",
        "\n",
        "      final_conversion_p = Scaled_positive_1000*0.25\n",
        "      final_conversion_n = Scaled_negative_100*0.50\n",
        "\n",
        "\n",
        "      Result = final_conversion_p-final_conversion_n\n",
        "      print(final_conversion_p,'\\n',final_conversion_n)\n",
        "      # Result = final_conversion_p\n",
        "      Result_new = Result*2.5\n",
        "      final_result = Result_new*100\n",
        "      print(f'Your final Audio Score is {final_result}')\n",
        "\n",
        "    else:\n",
        "        Average_positive = [pitch_mean,pitch_std,speech_rate]\n",
        "        Average_negative = [len(pauses),(silence_ratio*10)]\n",
        "\n",
        "\n",
        "        Scaled_positive = sum(Average_positive)/3\n",
        "        Scaled_negative = sum(Average_negative)/2\n",
        "\n",
        "        Scaled_positive_1000 = Scaled_positive/1000\n",
        "        Scaled_negative_100 = Scaled_negative/100\n",
        "\n",
        "\n",
        "        final_conversion_p = Scaled_positive_1000*0.25\n",
        "        final_conversion_n = Scaled_negative_100*0.50\n",
        "\n",
        "\n",
        "        Result = final_conversion_p-final_conversion_n\n",
        "        Result_new = Result*2.5\n",
        "        final_result = Result_new*100\n",
        "        # print(f'Your final Audio Score is {final_result}')\n",
        "\n",
        "\n",
        "        # print(scores)\n",
        "\n",
        "        if scores.count('Bad')>=2:\n",
        "          final_result_new = final_result/2\n",
        "          print(\"Your final audio score is \", final_result_new)\n",
        "        elif scores.count('Bad')==1:\n",
        "          decrease = final_result*(1/4)\n",
        "          final_result_new = final_result-decrease\n",
        "          print('Your final audio score is ',final_result_new)\n",
        "        else:\n",
        "          print('Your final audio score is ',final_result)\n",
        "    # print(f\"Results:{Result*2.5}\")\n",
        "    # print(f)\n",
        "\n",
        "    # print(Average_positive)\n",
        "\n",
        "    import os\n",
        "    from langchain.chains import ConversationChain\n",
        "    from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "    google_api_key = ''\n",
        "\n",
        "    # Llm model google genai\n",
        "    llm = ChatGoogleGenerativeAI(model='gemini-1.5-pro-latest', temperature=0.6, google_api_key=google_api_key)\n",
        "\n",
        "    # Set up memory and conversation chain\n",
        "    memory = ConversationBufferMemory()\n",
        "    conversation_chain = ConversationChain(llm=llm, memory=memory)\n",
        "\n",
        "    overall_text_score = ''\n",
        "    # Define the prompt for analysis\n",
        "    analysis_prompt = f\"\"\" {transcript} analysis the text based on grammar mistakes, fluency, clarity , professional tone and  overall rate it and rate out of 10 this is the text of interviewer analysis it completely Provide me only the scores don't give unnecessary text also detect irrelevant words and give me score if there are out of context words and drop overall score if there is irrelvancy store overall score in this variable{overall_text_score}\n",
        "\n",
        "    \"\"\"\n",
        "    print(overall_text_score)\n",
        "    def chat_with_bot(user_input):\n",
        "        # Format the analysis prompt with user input\n",
        "        formatted_prompt = analysis_prompt.format(text=user_input)\n",
        "        response = conversation_chain.run(input=formatted_prompt)\n",
        "        return response\n",
        "\n",
        "\n",
        "\n",
        "    output_text = chat_with_bot(user_input=analysis_prompt)\n",
        "    print(output_text)\n",
        "    print(f\"Your Audio Text score is \\n {chat_with_bot(user_input=analysis_prompt)}\")\n",
        "\n",
        "    print(overall_text_score,'overall_text score')\n",
        "    print(transcript)\n",
        "\n",
        "\n",
        "\n",
        "audio_file = \"/content/kanisha_n.wav\"\n",
        "analyze_audio(audio_file)\n",
        "# if __name__ == \"__main__\":\n",
        "#     audio_file = \"/content/kanisha_n.wav\"\n",
        "#     analyze_audio(audio_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNYApAp8ZwJB",
        "outputId": "45a584ca-ad0d-4a4e-932e-8e56523802d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grammar: 6/10\n",
            "Fluency: 7/10\n",
            "Clarity: 7/10\n",
            "Professional Tone: 6/10\n",
            "Overall: 6.5/10\n",
            "Irrelevance: 8/10 (Mentioning boyfriend and watching TV with family is irrelevant in this context)  This lowers the overall score due to the inclusion of personal, irrelevant details.\n",
            "\n",
            "**Final Overall (adjusted for irrelevance): 5.5/10**\n",
            "['5.5/10**']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "google_api_key = ''\n",
        "\n",
        "# Llm model google genai\n",
        "llm = ChatGoogleGenerativeAI(model='gemini-1.5-pro-latest', temperature=0.6, google_api_key=google_api_key)\n",
        "\n",
        "# Set up memory and conversation chain\n",
        "memory = ConversationBufferMemory()\n",
        "conversation_chain = ConversationChain(llm=llm, memory=memory)\n",
        "\n",
        "transcript = 'My name is Kanishka. I am currently pursuing my B.Com along with my studies. I have industrial experience working at Wisco HR Private Limited. This role has helped me in developing strong communication skills, teamwork and problem solving abilities. I am a quick learner, always looking to improve my skills and take on new challenges. I am excited to apply my knowledge and experience to a new role and contribute to a team. I am confident that my strong work ethic, positive attitude and passion of learning will make me a valuable asset to any organization. I am looking forward to discussing my qualification further. Thank you'\n",
        "transcript2 = 'My name is Kanishka. I am currently pursuing my B.Com along with my studies. I have industrial experience working at Wisco HR Private Limited. This role has helped me in developing strong communication skills, teamwork and problem solving abilities. I love playing cricket with my boyfriend and watching tv shows with family I enjoyed traveling and dancing. I am a quick learner, always looking to improve my skills and take on new challenges. I am excited to apply my knowledge and experience to a new role and contribute to a team. I am confident that my strong work ethic, positive attitude and passion of learning will make me a valuable asset to any organization. I am looking forward to discussing my qualification further. Thank you'\n",
        "# Define the prompt for analysis\n",
        "analysis_prompt = f\"\"\" {transcript2}\n",
        ".\n",
        "\n",
        "\"\"\"\n",
        "# print(overall_text_score)\n",
        "def chat_with_bot(user_input):\n",
        "    # Format the analysis prompt with user input\n",
        "    formatted_prompt = analysis_prompt.format(text=user_input)\n",
        "    response = conversation_chain.run(input=formatted_prompt)\n",
        "    return response\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "output_text = chat_with_bot(user_input=analysis_prompt)\n",
        "output = output_text.split(' ')\n",
        "final_output = output[-1::]\n",
        "print(output_text)\n",
        "print(final_output)\n",
        "\n",
        "# print(output_text)\n",
        "# print(f\"Your Audio Text score is \\n {chat_with_bot(user_input=analysis_prompt)}\")\n",
        "\n",
        "# # print(overall_text_score,'overall_text score')\n",
        "# print(transcript)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWk65QDXd4XN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQXOEorK58GV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JifWyZSmdKKV"
      },
      "outputs": [],
      "source": [
        "score = output_text.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AFNVgETjdPY8",
        "outputId": "ecb83f8e-59ea-47f7-d416-d6d9579610a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'5.5/10'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1arOsk4dPbp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-amlj3H57MQ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhSFLzwi57an"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NptMf6uI2W4",
        "outputId": "69a47c4a-b922-453e-ae42-caf78cc1bb95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hii\n"
          ]
        }
      ],
      "source": [
        "values = ['Good', 'Bad', 'Bad', 'Good', 'Good','Good']\n",
        "\n",
        "if values.count('Bad')==2:\n",
        "  print('hii')\n",
        "else:\n",
        "  print('no')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-QfaMgJNfgo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gTa669WJSd4"
      },
      "source": [
        " My name is Kaneshka. I am currently pursuing my BICOM along with my studies. I have industrial experience working at VSCO HR private limited. This role has helped me help me in develop strong communication skills, teamwork and problem-solving abilities. I am a quick learner always looking to improve my skills and take on new challenges. I am excited to apply my knowledge and experience to a new role and contribute to a team. I am confident that my strong work ethic, positive attitude and passion of learning will make me a valuable asset to any organization. I am looking forward to discussing my qualification further. Thank you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdLa-a9GZEy_"
      },
      "source": [
        "### ritik\n",
        "Transcribing audio with Whisper...\n",
        "{'frame_rate': 48000, 'n_frames': 3280896, 'duration': 68.352, 'average_loudness': 1594, 'silence_ratio': 0.3440546423903714, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 1063.82, Pitch Std: 984.70\n",
        "Speech Rate: 2.02 words per second\n",
        "Number of Pauses: 22\n",
        "Filler Count: 0\n",
        "Volume Mean: 0.04, Volume Std: 0.03\n",
        "Your final Audio Score is 25.14521660132057\n",
        "\n",
        "Your final Audio Score is 25.14521660132057\n",
        "Your Audio Text score is\n",
        " Grammar: 6/10\n",
        "Fluency: 7/10\n",
        "Clarity: 7/10\n",
        "Professional Tone: 6/10\n",
        "Overall: 6.5/10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnfZpHUEbL6w"
      },
      "source": [
        "atul\n",
        "Transcribing audio with Whisper...\n",
        "{'frame_rate': 48000, 'n_frames': 5020416, 'duration': 104.592, 'average_loudness': 2351, 'silence_ratio': 0.3117542450665443, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 1134.37, Pitch Std: 991.77\n",
        "Speech Rate: 1.49 words per second\n",
        "Number of Pauses: 18\n",
        "Filler Count: 1\n",
        "Volume Mean: 0.06, Volume Std: 0.05\n",
        "\n",
        "\n",
        "Your final Audio Score is 43.581676155780094\n",
        "  response = conversation_chain.run(input=formatted_prompt)\n",
        "Your Audio Text score is\n",
        " Grammar: 4/10\n",
        "Fluency: 3/10\n",
        "Clarity: 6/10\n",
        "Professional Tone: 4/10\n",
        "Overall: 4/10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-LJanbmcGQA"
      },
      "source": [
        "### hema\n",
        "Transcribing audio with Whisper...\n",
        "{'frame_rate': 44100, 'n_frames': 2850048, 'duration': 64.6269387755102, 'average_loudness': 3719, 'silence_ratio': 0.27156191755366926, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 1525.97, Pitch Std: 1129.75\n",
        "Speech Rate: 1.76 words per second\n",
        "Number of Pauses: 16\n",
        "Filler Count: 0\n",
        "Volume Mean: 0.08, Volume Std: 0.08\n",
        "\n",
        "\n",
        "Your final Audio Score is 76.23804714535592\n",
        "Your Audio Text score is\n",
        " Grammar: 6/10\n",
        "Fluency: 7/10\n",
        "Clarity: 7/10\n",
        "Professional Tone: 6/10\n",
        "Overall: 6.5/10\n",
        "\n",
        "\n",
        "\n",
        "### kanishka\n",
        "\n",
        "Transcribing audio with Whisper...\n",
        "{'frame_rate': 48000, 'n_frames': 2022912, 'duration': 42.144, 'average_loudness': 4791, 'silence_ratio': 0.23425981950771957, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 1289.36, Pitch Std: 1015.02\n",
        "Speech Rate: 2.56 words per second\n",
        "Number of Pauses: 0\n",
        "Filler Count: 0\n",
        "Volume Mean: 0.09, Volume Std: 0.06\n",
        "Your final Audio Score is 107.97709086067435\n",
        "Your Audio Text score is\n",
        " Grammar: 6/10\n",
        "Fluency: 7/10\n",
        "Clarity: 7/10\n",
        "Professional Tone: 8/10\n",
        "Overall: 7/10\n",
        "\n",
        "\n",
        "### Simran\n",
        "\n",
        "\n",
        "Transcribing audio with Whisper...\n",
        "{'frame_rate': 48000, 'n_frames': 2974936, 'duration': 61.977833333333336, 'average_loudness': 1086, 'silence_ratio': 0.3843765042340407, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 1110.78, Pitch Std: 1022.18\n",
        "Speech Rate: 2.32 words per second\n",
        "Number of Pauses: 10\n",
        "Filler Count: 0\n",
        "Volume Mean: 0.03, Volume Std: 0.02\n",
        "\n",
        "Your final Audio Score is 33.02773004044332\n",
        "Your Audio Text score is\n",
        " Grammar: 6/10\n",
        "Fluency: 7/10\n",
        "Clarity: 8/10\n",
        "Professional Tone: 6/10\n",
        "Overall: 7/10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvY0leCsAE8-"
      },
      "source": [
        "### Diksha\n",
        "Transcribing audio with Whisper...\n",
        "{'frame_rate': 48000, 'n_frames': 1918976, 'duration': 39.97866666666667, 'average_loudness': 2163, 'silence_ratio': 0.3077491589264274, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 1012.19, Pitch Std: 874.93\n",
        "Speech Rate: 2.50 words per second\n",
        "Number of Pauses: 4\n",
        "Filler Count: 0\n",
        "Volume Mean: 0.05, Volume Std: 0.03\n",
        "\n",
        "Your final Audio Score is 54.47535331831925\n",
        "Your Audio Text score is\n",
        " Grammar: 4/10\n",
        "Fluency: 3/10\n",
        "Clarity: 3/10\n",
        "Professional Tone: 4/10\n",
        "Overall: 3.5/10\n",
        "\n",
        "### UPSE\n",
        "Transcribing audio with Whisper...\n",
        "{'frame_rate': 48000, 'n_frames': 3510528, 'duration': 73.136, 'average_loudness': 1816, 'silence_ratio': 0.3303266631116459, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 1090.25, Pitch Std: 1042.80\n",
        "Speech Rate: 3.19 words per second\n",
        "Number of Pauses: 17\n",
        "Filler Count: 0\n",
        "Volume Mean: 0.04, Volume Std: 0.04\n",
        "Your final Audio Score is 36.374594931337164\n",
        "\n",
        "### Fraction1\n",
        "{'frame_rate': 44100, 'n_frames': 3376128, 'duration': 76.55619047619048, 'average_loudness': 747, 'silence_ratio': 0.4308845073409539, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 1004.19, Pitch Std: 1139.31\n",
        "Speech Rate: 2.47 words per second\n",
        "Number of Pauses: 22\n",
        "Filler Count: 0\n",
        "Volume Mean: 0.02, Volume Std: 0.01\n",
        "Your final Audio Score is 12.316524498962366\n",
        "\n",
        "### Fraction2\n",
        "Transcribing audio with Whisper...\n",
        "{'frame_rate': 44100, 'n_frames': 3598336, 'duration': 81.59492063492064, 'average_loudness': 1304, 'silence_ratio': 0.3922793758003699, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 1090.03, Pitch Std: 1072.64\n",
        "Speech Rate: 2.19 words per second\n",
        "Number of Pauses: 15\n",
        "Filler Count: 0\n",
        "Volume Mean: 0.02, Volume Std: 0.02\n",
        "Your final Audio Score is 30.54754294871469-\n",
        "\n",
        "\n",
        "### Upse2\n",
        "{'frame_rate': 48000, 'n_frames': 1532064, 'duration': 31.918, 'average_loudness': 2869, 'silence_ratio': 0.27840090231217496, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 954.44, Pitch Std: 864.69\n",
        "Speech Rate: 3.01 words per second\n",
        "Number of Pauses: 9\n",
        "Filler Count: 0\n",
        "Volume Mean: 0.07, Volume Std: 0.06\n",
        "Your final Audio Score is 58.56900879745011\n",
        "\n",
        "### Rahul_new\n",
        "{'frame_rate': 48000, 'n_frames': 2856856, 'duration': 59.517833333333336, 'average_loudness': 1450, 'silence_ratio': 0.38694809958919874, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 1174.07, Pitch Std: 971.45\n",
        "Speech Rate: 2.15 words per second\n",
        "Number of Pauses: 18\n",
        "Filler Count: 0\n",
        "Volume Mean: 0.03, Volume Std: 0.03\n",
        "Transcript:  I am Rahul Dharmare, a graphic designer with a passion for creativity. I studied graphic design at Zika Indore and also have a Bachelor of Commerce degree from Vikram University. Along the way, I have learned photo editing and video editing and like app designing and website designing. Apart from designing, I also sketch. I am also a sketch artist. I love drawing and bringing ideas to life on paper. Whether it's creating a logo design, a website or sketching something just for fun. I enjoy every part of the creative process. For me, design isn't just a work, it's something I truly love doing. I am always exploring new styles, learning new things and pushing myself to get better every day excited to keep growing and creating.\n",
        "Your final Audio Score is 28.876778183296064\n",
        "\n",
        "### Atul_new_fast\n",
        "Transcribing audio with Whisper...\n",
        "{'frame_rate': 48000, 'n_frames': 4526208, 'duration': 94.296, 'average_loudness': 3428, 'silence_ratio': 0.24767774702355702, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 1149.67, Pitch Std: 999.04\n",
        "Speech Rate: 2.45 words per second\n",
        "Number of Pauses: 6\n",
        "Filler Count: 1\n",
        "Volume Mean: 0.08, Volume Std: 0.06\n",
        "Your final Audio Score is 48.37588409889537"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svQLEUfiE5z1"
      },
      "source": [
        "### aleena_youtube\n",
        "Transcribing audio with Whisper...\n",
        "{'frame_rate': 48000, 'n_frames': 34468463, 'duration': 718.0929791666666, 'average_loudness': 4481, 'silence_ratio': 0.21236474919116644, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 1726.77, Pitch Std: 1099.83\n",
        "Speech Rate: 2.74 words per second\n",
        "Number of Pauses: 45\n",
        "Filler Count: 4\n",
        "Volume Mean: 0.11, Volume Std: 0.09\n",
        "Your final Audio Score is 12.427740665212433,  55.319\n",
        "\n",
        "\n",
        "### Elevenlab_new\n",
        "{'frame_rate': 44100, 'n_frames': 6141312, 'duration': 139.2587755102041, 'average_loudness': 882, 'silence_ratio': 0.43401019195898205, 'speech_detected': True}\n",
        "Analysis Results:\n",
        "Pitch Mean: 1656.85, Pitch Std: 1063.14\n",
        "Speech Rate: 2.03 words per second\n",
        "Number of Pauses: 58\n",
        "Filler Count: 0\n",
        "Volume Mean: 0.02, Volume Std: 0.02\n",
        "Average\n",
        "0.19768812452411813\n",
        " 0.15585025479897455\n",
        "Your final Audio Score is 10.459467431285896"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gn6bFyLeiJs3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wrAIZE4I2aS"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#   number = int(input('Enter your number'))\n",
        "# except :\n",
        "#   print('this is not valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VABCCQsZI2e_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9_f6YCQOqWi"
      },
      "source": [
        "## Background noise and Breathe detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV3Lfv1VUG-e",
        "outputId": "ab7ba5ed-47ee-4703-8393-ff692af98c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting noisereduce\n",
            "  Downloading noisereduce-3.0.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from noisereduce) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from noisereduce) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from noisereduce) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from noisereduce) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from noisereduce) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.17.0)\n",
            "Downloading noisereduce-3.0.3-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: noisereduce\n",
            "Successfully installed noisereduce-3.0.3\n"
          ]
        }
      ],
      "source": [
        "pip install noisereduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_dNUZi3UHCF"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "from scipy.io import wavfile\n",
        "import noisereduce as nr\n",
        "import soundfile as sf\n",
        "from noisereduce.generate_noise import band_limited_noise\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "dJpBIf6jPAr5",
        "outputId": "b9233c5b-16a6-4602-9f80-d552b8265cd5"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'read'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-78b62235485b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/hema_new.wav\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# response = urllib.request.urlopen(url)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'"
          ]
        }
      ],
      "source": [
        "url = \"/content/hema_new.wav\"\n",
        "# response = urllib.request.urlopen(url)\n",
        "data, rate = sf.read(io.BytesIO(url.read()))\n",
        "data = data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjM8KgOTUntI"
      },
      "outputs": [],
      "source": [
        "url = '/content/hema_new.wav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "xcwJ-uQPUjU3",
        "outputId": "c3dec630-764b-4f3e-bd63-8674aa7ef426"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'rate' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-41ea19edcda3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'rate' is not defined"
          ]
        }
      ],
      "source": [
        "IPython.display.Audio(url, rate=rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCis740uOw4Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGcpTWVgOw7R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tqbal9-nOw-K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw9rfh9qOxBZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWT_rp1nOxEg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hov5QmxZOyM5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETG99nHsOyPx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqZlXeRzOySO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p8DTa5CVlNG"
      },
      "source": [
        "### Text information Extraction  from the audio text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbpgh5HVVwtq",
        "outputId": "77e3cd77-d317-4707-b419-81645baae849"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:26<00:00, 58.6MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribing audio with Whisper...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-964deb66aa88>:29: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n",
            "<ipython-input-4-964deb66aa88>:30: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  conversation_chain = ConversationChain(llm=llm, memory=memory)\n",
            "<ipython-input-4-964deb66aa88>:41: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = conversation_chain.run(input=formatted_prompt)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your Audio Text score is \n",
            " Atul Kumar Patel's self-introduction reveals the following information:\n",
            "\n",
            "**Personal Information:**\n",
            "\n",
            "* **Name:** Atul Kumar Patel\n",
            "\n",
            "**Education:**\n",
            "\n",
            "* **Bachelor of Science:**  UPS APS University, Rewa (It's likely \"Rewa,\" not \"Riva\")\n",
            "* **Master's in Geology:** Holkar Science College, Indore\n",
            "* **Post Graduate Diploma (PGD):**  M. Chaturvedi University, Bhopal.  (The specific subject of the PGD isn't mentioned, which might be helpful context.)\n",
            "* **Data Analytics Certification:** Volcanos Academy, Indore\n",
            "\n",
            "**Experience:**\n",
            "\n",
            "* **Current Role:** Data Analyst at VSCO Group, Indore. (While VSCO is a known photo/video editing app company, having an office in Indore seems unusual.  It's possible this is a different company with the same acronym or a typo.)\n",
            "* **Responsibilities:**  Gathering, processing, and analyzing large datasets to support data-driven decision-making. Creating data visualizations and reports.\n",
            "\n",
            "**Skills:**\n",
            "\n",
            "* **Tools:** Power BI, Tableau, Excel, SQL\n",
            "* **Programming Languages:** Python\n",
            "* **Other:** Statistics, Data Analysis, Business Intelligence, Machine Learning, Model Building\n",
            "\n",
            "**Interests:**\n",
            "\n",
            "* Cricket, Music, Exploring new places, Problem-solving\n",
            "\n",
            "**Career Goals:**\n",
            "\n",
            "* Continuous learning and application of data analysis skills to help companies succeed.\n",
            "\n",
            "\n",
            "**Potential Inconsistencies/Points for Clarification:**\n",
            "\n",
            "* **VSCO Group, Indore:**  As mentioned, this requires verification.  VSCO's main presence is online and doesn't list an Indore office on their website.\n",
            "* **Master's in Geology and Data Analysis Career:** While not impossible, it's an unusual combination.  It's possible Atul transitioned careers or the PGD bridged this gap. Clarifying the PGD subject would be helpful.\n",
            "* **\"Gathering process\"**: This phrase is grammatically incorrect and should likely be \"gathering and processing\" data.\n",
            "\n",
            "\n",
            "This summary highlights the key details and also flags potential areas where further clarification might be needed. This is particularly important if this introduction is being used for a job application or professional networking.\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "import warnings\n",
        "\n",
        "whisper_model = whisper.load_model(\"medium\")\n",
        "#Audio to text using Whisper\n",
        "def transcribe_audio_whisper(file_path):\n",
        "    warnings.filterwarnings(\"ignore\", message=\"You are using `torch.load` with `weights_only=False`\")\n",
        "    print(\"Transcribing audio with Whisper...\")\n",
        "    result = whisper_model.transcribe(file_path, fp16=False)\n",
        "    return result[\"text\"]\n",
        "\n",
        "\n",
        "text = transcribe_audio_whisper(file_path='/content/atul_new_slow.wav')\n",
        "\n",
        "\n",
        "import os\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model='gemini-1.5-pro-latest', temperature=0.6, google_api_key=google_api_key)\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "conversation_chain = ConversationChain(llm=llm, memory=memory)\n",
        "\n",
        "\n",
        "analysis_prompt = f\"\"\" {text} Analysis the text this is the text of a self introduction of candidate Identify important information from this text like candidate name candidate experience and other details that are important correct details if its seems incorrect like degree name experience skills name\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def chat_with_bot(user_input):\n",
        "    # Format the analysis prompt with user input\n",
        "    formatted_prompt = analysis_prompt.format(text=user_input)\n",
        "    response = conversation_chain.run(input=formatted_prompt)\n",
        "    return response\n",
        "\n",
        "print(f\"Your Audio Text score is \\n {chat_with_bot(user_input=analysis_prompt)}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETsynTl5wQv-"
      },
      "source": [
        "## Whisper small model\n",
        " My name is Sathur Kumar Bhattel. I am a dedicated and result driven data analyst with a strong background in data analysis, business intelligence and machine learning. My academic journey began with a bachelor of science and from UP. APS University, Riva followed by master's degree in geology from Holker Science College in the world. It expanded my technical knowledge. I also completed a PGDC from Markanlal Chaturvedi University, Bhopal and certified data analytics course from Volcanus Academy in Dore. Currently, I work at VSCO Group in Dore as a data analyst where I specialize in a gathering process and analyze large data set to help company and data driven decision. I have hands-on expertise in a tool like Power BI, Tableau, Excel and SQL to data visualizations and reporting along with Python and statistics for deeper analysis and model building. In my free time, I love playing cricket, listening music and exploring new places. I enjoy solving complex problems using data and take pride in presenting inside that drive business growth. My goal is to continue to learn and apply my knowledge to help companies stay ahead of the curve in today's data driven world."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MLrsyaOwZVM"
      },
      "source": [
        "### Whisper medium model\n",
        " My name is Atul Kumar Patel. I am a dedicated and result-driven data analyst with a strong background in data analysis, business intelligence and machine learning. My academic journey began with a Bachelor of Science and from UPS APS University, Riva, followed by a Master's degree in Geology from Holkar Science College, Indore. It expanded my technical knowledge. I also completed PGD from M. Chaturvedi University, Bhopal and certified data analytics course from Volcanos Academy, Indore. Currently, I work at VSCO Group, Indore as a data analyst where I specialize in gathering process and analyze large data sets to help company and data-driven decision. I have hands-on expertise in a tool like Power BI, Tableau, Excel and SQL to data visualizations and reporting along with Python and statistics for deeper analysis and model building. In my free time, I love playing cricket, listening music and exploring new places. I enjoy solving complex problems using data and take pride in presenting insights that drive business growth. My goal is to continue to learn and apply my knowledge to help companies stay ahead of the curve in today's data-driven world."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-kvsTCaWRZU",
        "outputId": "306463d8-032a-45b3-fb90-34c96bdf6693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " My name is Atul Kumar Patel. I am a dedicated and result-driven data analyst with a strong background in data analysis, business intelligence and machine learning. My academic journey began with a Bachelor of Science and from UPS APS University, Riva, followed by a Master's degree in Geology from Holkar Science College, Indore. It expanded my technical knowledge. I also completed PGD from M. Chaturvedi University, Bhopal and certified data analytics course from Volcanos Academy, Indore. Currently, I work at VSCO Group, Indore as a data analyst where I specialize in gathering process and analyze large data sets to help company and data-driven decision. I have hands-on expertise in a tool like Power BI, Tableau, Excel and SQL to data visualizations and reporting along with Python and statistics for deeper analysis and model building. In my free time, I love playing cricket, listening music and exploring new places. I enjoy solving complex problems using data and take pride in presenting insights that drive business growth. My goal is to continue to learn and apply my knowledge to help companies stay ahead of the curve in today's data-driven world.\n"
          ]
        }
      ],
      "source": [
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GoWbJwKa_19"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uBLqHZca_5T"
      },
      "outputs": [],
      "source": [
        "data=[{\n",
        "    \"name\": \"litik\",\n",
        "    \"designation\": \"AI\",\n",
        "    \"salary\": 60000,\n",
        "    \"location\": \"Italy\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"rulali\",\n",
        "    \"designation\": \"Backend\",\n",
        "    \"salary\": 12000,\n",
        "    \"location\": \"India\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"lulul\",\n",
        "    \"designation\": \"Analysis\",\n",
        "    \"salary\": 80000,\n",
        "    \"location\": \"UAE\"\n",
        "  },\n",
        "  {\n",
        "    \"name\": \"lakacha\",\n",
        "    \"designation\": \"Backend\",\n",
        "    \"salary\": 50000,\n",
        "    \"location\": \"Germany\"\n",
        "  }]\n",
        "\n",
        "df=pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "-31AIYexbHVT",
        "outputId": "7406679a-7239-4779-80c2-d1546612e211"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"rulali\",\n          \"lakacha\",\n          \"litik\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"designation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"AI\",\n          \"Backend\",\n          \"Analysis\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28536,\n        \"min\": 12000,\n        \"max\": 80000,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          12000,\n          50000,\n          60000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"India\",\n          \"Germany\",\n          \"Italy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ad339af3-c68e-4458-a8c6-b415a4f6b650\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>designation</th>\n",
              "      <th>salary</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>litik</td>\n",
              "      <td>AI</td>\n",
              "      <td>60000</td>\n",
              "      <td>Italy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rulali</td>\n",
              "      <td>Backend</td>\n",
              "      <td>12000</td>\n",
              "      <td>India</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lulul</td>\n",
              "      <td>Analysis</td>\n",
              "      <td>80000</td>\n",
              "      <td>UAE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lakacha</td>\n",
              "      <td>Backend</td>\n",
              "      <td>50000</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad339af3-c68e-4458-a8c6-b415a4f6b650')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad339af3-c68e-4458-a8c6-b415a4f6b650 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad339af3-c68e-4458-a8c6-b415a4f6b650');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ebee9ff6-5ed0-4105-b3e7-ae6672adb001\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ebee9ff6-5ed0-4105-b3e7-ae6672adb001')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ebee9ff6-5ed0-4105-b3e7-ae6672adb001 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f7982b02-46cb-4dbc-b21d-4682997fbba9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f7982b02-46cb-4dbc-b21d-4682997fbba9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      name designation  salary location\n",
              "0    litik          AI   60000    Italy\n",
              "1   rulali     Backend   12000    India\n",
              "2    lulul    Analysis   80000      UAE\n",
              "3  lakacha     Backend   50000  Germany"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqN2F2noBpdS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPdiKf36dzLG",
        "outputId": "948c85f2-3981-4cab-81b6-a514167cf3d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name\n",
            "designation\n",
            "salary\n",
            "location\n"
          ]
        }
      ],
      "source": [
        "for i in df:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5la8b8R7bLQt"
      },
      "outputs": [],
      "source": [
        "# df[df['designation','salary']]=='Backend',50000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "P-I5HYzzdVqV",
        "outputId": "bd23a679-8955-484f-8b44-737097b3e300"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df[df['salary']==50000]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"lakacha\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"designation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Backend\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 50000,\n        \"max\": 50000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          50000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Germany\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8cab8425-5917-4eb7-a29d-5de4b0ba4321\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>designation</th>\n",
              "      <th>salary</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lakacha</td>\n",
              "      <td>Backend</td>\n",
              "      <td>50000</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cab8425-5917-4eb7-a29d-5de4b0ba4321')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8cab8425-5917-4eb7-a29d-5de4b0ba4321 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8cab8425-5917-4eb7-a29d-5de4b0ba4321');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      name designation  salary location\n",
              "3  lakacha     Backend   50000  Germany"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['salary']==50000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "u_0bHFoUbSjZ",
        "outputId": "df8ecbc2-51d9-4ce8-993f-f71b3e0343a4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df[df['designation']=='Backend']\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"lakacha\",\n          \"rulali\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"designation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Backend\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26870,\n        \"min\": 12000,\n        \"max\": 50000,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Germany\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-742bf6cf-7c0c-41d3-98ab-6ddb5ee9aafb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>designation</th>\n",
              "      <th>salary</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rulali</td>\n",
              "      <td>Backend</td>\n",
              "      <td>12000</td>\n",
              "      <td>India</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lakacha</td>\n",
              "      <td>Backend</td>\n",
              "      <td>50000</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-742bf6cf-7c0c-41d3-98ab-6ddb5ee9aafb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-742bf6cf-7c0c-41d3-98ab-6ddb5ee9aafb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-742bf6cf-7c0c-41d3-98ab-6ddb5ee9aafb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6cd0f8f1-cfad-4c16-872e-ce7ef2963953\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6cd0f8f1-cfad-4c16-872e-ce7ef2963953')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6cd0f8f1-cfad-4c16-872e-ce7ef2963953 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      name designation  salary location\n",
              "1   rulali     Backend   12000    India\n",
              "3  lakacha     Backend   50000  Germany"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['designation']=='Backend']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8WNCCvpcyDt"
      },
      "outputs": [],
      "source": [
        "if"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "506GrObVbYvZ"
      },
      "outputs": [],
      "source": [
        "df[df['designation']=='Backend']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltGUYk4rb9wy"
      },
      "outputs": [],
      "source": [
        "# df.loc['designation']=='Backend'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWM19R8KceOB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jyef38hFxDwt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lWSRZHyxDzg"
      },
      "outputs": [],
      "source": [
        "k = 'ritik bhaws from indore'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCGMTYW4x3hm",
        "outputId": "2162b20f-1cd3-4c73-99d3-eab25d3a870e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(k.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdvMSJbPxD2A",
        "outputId": "e3f36271-7cd1-4051-fc32-891422a0d143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "indore\n"
          ]
        }
      ],
      "source": [
        "var = k.split()\n",
        "inter = []\n",
        "for i in range(len(k.split())):\n",
        "  inter.append(len(var[i]))\n",
        "\n",
        "print(inter.index(max(inter)))\n",
        "print(var[inter.index(max(inter))])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N12TNVY2xD46"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
